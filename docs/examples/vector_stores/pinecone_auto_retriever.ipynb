{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cf577bb",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/vector_stores/pinecone_auto_retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "307804a3-c02b-4a57-ac0d-172c30ddc851",
   "metadata": {},
   "source": [
    "# Auto Retriever (with Pinecone + Arize Phoenix)\n",
    "\n",
    "In this notebook we showcase how to perform **auto-retrieval** against Pinecone, which lets you execute a broad range of semi-structured queries beyond what you can do with standard top-k semantic search.\n",
    "\n",
    "The steps are the following:\n",
    "1. We'll do some setup, load data, build a Pinecone vector index.\n",
    "2. We'll define our autoretriever and run some sample queries.\n",
    "3. We'll use Phoenix to observe each trace and visualize the prompt inputs/outputs.\n",
    "4. We'll show you how to customize the auto-retrieval prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e97ec52a",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ü¶ô."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08012b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index scikit-learn arize-phoenix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396",
   "metadata": {},
   "source": [
    "## 1. Setup Pinecone/Phoenix, Load Data, and Build Vector Index\n",
    "\n",
    "In this section we setup pinecone and ingest some toy data on books/movies (with text data and metadata).\n",
    "\n",
    "We also setup Phoenix so that it captures downstream traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70609af-1ccb-48de-8cb2-335eb783143f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://127.0.0.1:6006/\n",
      "üì∫ To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "# setup Phoenix\n",
    "import phoenix as px\n",
    "import llama_index\n",
    "\n",
    "px.launch_app()\n",
    "llama_index.set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48af8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062610f-8ad0-4ef9-a0e8-aaafc66ad71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad14111-0bbb-4c62-906d-6d6253e0cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "api_key = os.environ[\"PINECONE_API_KEY\"]\n",
    "pinecone.init(api_key=api_key, environment=\"gcp-starter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c90087-bdd9-4ca4-b06b-2af883559f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions are for text-embedding-ada-002\n",
    "try:\n",
    "    pinecone.create_index(\n",
    "        \"quickstart-index\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    # most likely index already exists\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667f3cb3-ce18-48d5-b9aa-bfc1a1f0f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_index = pinecone.Index(\"quickstart-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c7673-5664-4cde-abe3-32fe82169a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: delete data in your pinecone index\n",
    "pinecone_index.delete(delete_all=True, namespace=\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
   "metadata": {},
   "source": [
    "#### Load documents, build the PineconeVectorStore and VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bcc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae59590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import TextNode\n",
    "\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=\"The Shawshank Redemption\",\n",
    "        metadata={\n",
    "            \"author\": \"Stephen King\",\n",
    "            \"theme\": \"Friendship\",\n",
    "            \"year\": 1994,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"The Godfather\",\n",
    "        metadata={\n",
    "            \"director\": \"Francis Ford Coppola\",\n",
    "            \"theme\": \"Mafia\",\n",
    "            \"year\": 1972,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Inception\",\n",
    "        metadata={\n",
    "            \"director\": \"Christopher Nolan\",\n",
    "            \"theme\": \"Fiction\",\n",
    "            \"year\": 2010,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"To Kill a Mockingbird\",\n",
    "        metadata={\n",
    "            \"author\": \"Harper Lee\",\n",
    "            \"theme\": \"Mafia\",\n",
    "            \"year\": 1960,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"1984\",\n",
    "        metadata={\n",
    "            \"author\": \"George Orwell\",\n",
    "            \"theme\": \"Totalitarianism\",\n",
    "            \"year\": 1949,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"The Great Gatsby\",\n",
    "        metadata={\n",
    "            \"author\": \"F. Scott Fitzgerald\",\n",
    "            \"theme\": \"The American Dream\",\n",
    "            \"year\": 1925,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Harry Potter and the Sorcerer's Stone\",\n",
    "        metadata={\n",
    "            \"author\": \"J.K. Rowling\",\n",
    "            \"theme\": \"Fiction\",\n",
    "            \"year\": 1997,\n",
    "        },\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6eeecb-d54f-4a71-b5fe-0cda8a5c3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore(\n",
    "    pinecone_index=pinecone_index,\n",
    "    namespace=\"test\",\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad08884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a867f00827a84ec09ba00dfeed0f2b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e3c36-eed0-4cd1-953f-116f6e33b123",
   "metadata": {},
   "source": [
    "## 2. Define Autoretriever, Run Some Sample Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c388e1fd-e897-42b5-ba64-5e6dea874668",
   "metadata": {},
   "source": [
    "### Setup the `VectorIndexAutoRetriever`\n",
    "\n",
    "One of the inputs is a `schema` describing what content the vector store collection contains. This is similar to a table schema describing a table in the SQL database. This schema information is then injected into the prompt, which is passed to the LLM to infer what the full query should be (including metadata filters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.vector_store.retrievers import (\n",
    "    VectorIndexAutoRetriever,\n",
    ")\n",
    "from llama_index.vector_stores.types import MetadataInfo, VectorStoreInfo\n",
    "\n",
    "\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"famous books and movies\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"director\",\n",
    "            type=\"str\",\n",
    "            description=(\"Name of the director\"),\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"theme\",\n",
    "            type=\"str\",\n",
    "            description=(\"Theme of the book/movie\"),\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"year\",\n",
    "            type=\"int\",\n",
    "            description=(\"Year of the book/movie\"),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "retriever = VectorIndexAutoRetriever(\n",
    "    index,\n",
    "    vector_store_info=vector_store_info,\n",
    "    empty_query_top_k=10,\n",
    "    # this is a hack to allow for blank queries in pinecone\n",
    "    default_empty_query_vector=[0] * 1536,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d73c3-51fd-4191-84f9-14dcaf35a287",
   "metadata": {},
   "source": [
    "### Let's run some queries\n",
    "\n",
    "Let's run some sample queries that make use of the structured information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a0453a-fbc4-446c-879f-340040247f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever.retrieve(\n",
    "    \"Tell me about some books/movies after the year 2000\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3b724-e7a3-464a-962e-8c2c8e6e2e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "director: Christopher Nolan\n",
      "theme: Fiction\n",
      "year: 2010\n",
      "\n",
      "Inception\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node.get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever.retrieve(\"Tell me about some books that are Fiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222e259-3146-4c79-9491-fe8453f0cf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ea857713-2f12-4458-b920-3d1cf78689db\n",
      "director: Christopher Nolan\n",
      "theme: Fiction\n",
      "year: 2010\n",
      "\n",
      "Inception\n",
      "facf4f48-cac6-4efb-a11c-362d26e56aea\n",
      "author: J.K. Rowling\n",
      "theme: Fiction\n",
      "year: 1997\n",
      "\n",
      "Harry Potter and the Sorcerer's Stone\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node.id_)\n",
    "    print(node.get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1ec4bb-8b20-476f-a21c-6d895fbe7ef9",
   "metadata": {},
   "source": [
    "#### Pass in Additional Metadata Filters\n",
    "\n",
    "If you have additional metadata filters you want to pass in that aren't autoinferred, do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0761b152-f91e-4233-b47e-f9564cb14eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores import MetadataFilters\n",
    "\n",
    "filter_dicts = [{\"key\": \"year\", \"operator\": \"==\", \"value\": 1997}]\n",
    "filters = MetadataFilters.from_dicts(filter_dicts)\n",
    "retriever2 = VectorIndexAutoRetriever(\n",
    "    index,\n",
    "    vector_store_info=vector_store_info,\n",
    "    empty_query_top_k=10,\n",
    "    # this is a hack to allow for blank queries in pinecone\n",
    "    default_empty_query_vector=[0] * 1536,\n",
    "    extra_filters=filters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a35a85-97fa-45bb-87a5-aee5c1b134ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever2.retrieve(\"Tell me about some books that are Fiction\")\n",
    "for node in nodes:\n",
    "    print(node.id_)\n",
    "    print(node.get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f3907-180c-4bf1-b414-a34bc552708e",
   "metadata": {},
   "source": [
    "#### Example of a failing Query\n",
    "\n",
    "Note that no results are retrieved! We'll fix this later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f772b3-b455-4afe-8312-8b16fd989fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using query str: books\n",
      "Using query str: books\n",
      "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using filters: [('theme', '==', 'mafia')]\n",
      "Using filters: [('theme', '==', 'mafia')]\n",
      "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using top_k: 2\n",
      "Using top_k: 2\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\"Tell me about some books that are mafia-themed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13877106-8f8a-43f9-a624-789a2c1be4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    print(node.id_)\n",
    "    print(node.get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f00668-0316-468b-a57c-2d999d319df8",
   "metadata": {},
   "source": [
    "### Visualize Traces\n",
    "\n",
    "Let's open up Phoenix to take a look at the traces! \n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1PCEwIdv7GcInk3i6ebd2WWjTp9ducG5F\"/>\n",
    "\n",
    "Let's take a look at the auto-retrieval prompt. We see that the auto-retrieval prompt makes use of two few-shot examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8718ff-b3fa-4430-af69-0a0f31e38a09",
   "metadata": {},
   "source": [
    "## Improve the Auto-retrieval Prompt\n",
    "\n",
    "Our auto-retrieval prompt works, but it can be improved in various ways. Some examples include the fact that it includes 2 hardcoded few-shot examples (how can you include your own?), and also the fact that the auto-retrieval doesn't \"always\" infer the right metadata filters.\n",
    "\n",
    "For instance, all the `theme` fields are capitalized. How do we tell the LLM that, so it doesn't erroneously infer a \"theme\" that's in lower-case? \n",
    "\n",
    "Let's take a stab at modifying the prompt! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc818138-c1f4-401b-95bb-680db43f8508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.prompts import display_prompt_dict, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87445682-4330-4eee-acff-c06b20781b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_dict = retriever.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab823b-f6a1-4071-b57c-7357c62709c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: prompt<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your goal is to structure the user's query to match the request schema provided below.\n",
      "\n",
      "<< Structured Request Schema >>\n",
      "When responding use a markdown code snippet with a JSON object formatted in the following schema:\n",
      "\n",
      "{schema_str}\n",
      "\n",
      "The query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\n",
      "\n",
      "Make sure that filters only refer to attributes that exist in the data source.\n",
      "Make sure that filters take into account the descriptions of attributes.\n",
      "Make sure that filters are only used as needed. If there are no filters that should be applied return [] for the filter value.\n",
      "If the user's query explicitly mentions number of documents to retrieve, set top_k to that number, otherwise do not set top_k.\n",
      "\n",
      "<< Example 1. >>\n",
      "Data Source:\n",
      "```json\n",
      "{{\n",
      "    \"metadata_info\": [\n",
      "        {{\n",
      "            \"name\": \"artist\",\n",
      "            \"type\": \"str\",\n",
      "            \"description\": \"Name of the song artist\"\n",
      "        }},\n",
      "        {{\n",
      "            \"name\": \"genre\",\n",
      "            \"type\": \"str\",\n",
      "            \"description\": \"The song genre, one of \\\"pop\\\", \\\"rock\\\" or \\\"rap\\\"\"\n",
      "        }}\n",
      "    ],\n",
      "    \"content_info\": \"Lyrics of a song\"\n",
      "}}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What are songs by Taylor Swift or Katy Perry in the dance pop genre\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{{\"query\": \"teenager love\", \"filters\": [{{\"key\": \"artist\", \"value\": \"Taylor Swift\", \"operator\": \"==\"}}, {{\"key\": \"artist\", \"value\": \"Katy Perry\", \"operator\": \"==\"}}, {{\"key\": \"genre\", \"value\": \"pop\", \"operator\": \"==\"}}], \"top_k\": null}}\n",
      "\n",
      "\n",
      "<< Example 2. >>\n",
      "Data Source:\n",
      "```json\n",
      "{{\n",
      "    \"metadata_info\": [\n",
      "        {{\n",
      "            \"name\": \"author\",\n",
      "            \"type\": \"str\",\n",
      "            \"description\": \"Author name\"\n",
      "        }},\n",
      "        {{\n",
      "            \"name\": \"book_title\",\n",
      "            \"type\": \"str\",\n",
      "            \"description\": \"Book title\"\n",
      "        }},\n",
      "        {{\n",
      "            \"name\": \"year\",\n",
      "            \"type\": \"int\",\n",
      "            \"description\": \"Year Published\"\n",
      "        }},\n",
      "        {{\n",
      "            \"name\": \"pages\",\n",
      "            \"type\": \"int\",\n",
      "            \"description\": \"Number of pages\"\n",
      "        }},\n",
      "        {{\n",
      "            \"name\": \"summary\",\n",
      "            \"type\": \"str\",\n",
      "            \"description\": \"A short summary of the book\"\n",
      "        }}\n",
      "    ],\n",
      "    \"content_info\": \"Classic literature\"\n",
      "}}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What are some books by Jane Austen published after 1813 that explore the theme of marriage for social standing?\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{{\"query\": \"Books related to theme of marriage for social standing\", \"filters\": [{{\"key\": \"year\", \"value\": \"1813\", \"operator\": \">\"}}, {{\"key\": \"author\", \"value\": \"Jane Austen\", \"operator\": \"==\"}}], \"top_k\": null}}\n",
      "\n",
      "```\n",
      "\n",
      "<< Example 3. >>\n",
      "Data Source:\n",
      "```json\n",
      "{info_str}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "{query_str}\n",
      "\n",
      "Structured Request:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d97d40-b953-4b5e-83c1-9f06dc069bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['schema_str', 'info_str', 'query_str']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at required template variables.\n",
    "prompts_dict[\"prompt\"].template_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4cadea-337a-498e-bb85-fac0efc95ad8",
   "metadata": {},
   "source": [
    "### Customize the Prompt\n",
    "\n",
    "Let's customize the prompt a little bit. We do the following:\n",
    "- Take out the first few-shot example to save tokens\n",
    "- Add a message to always capitalize a letter if inferring \"theme\".\n",
    "\n",
    "Note that the prompt template expects `schema_str`, `info_str`, and `query_str` to be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1bfd0c-7bba-4a78-b273-bde378a7b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write prompt template, and modify it.\n",
    "\n",
    "prompt_tmpl_str = \"\"\"\\\n",
    "Your goal is to structure the user's query to match the request schema provided below.\n",
    "\n",
    "<< Structured Request Schema >>\n",
    "When responding use a markdown code snippet with a JSON object formatted in the following schema:\n",
    "\n",
    "{schema_str}\n",
    "\n",
    "The query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\n",
    "\n",
    "Make sure that filters only refer to attributes that exist in the data source.\n",
    "Make sure that filters take into account the descriptions of attributes.\n",
    "Make sure that filters are only used as needed. If there are no filters that should be applied return [] for the filter value.\n",
    "If the user's query explicitly mentions number of documents to retrieve, set top_k to that number, otherwise do not set top_k.\n",
    "\n",
    "<< Example 1. >>\n",
    "Data Source:\n",
    "```json\n",
    "{{\n",
    "    \"metadata_info\": [\n",
    "        {{\n",
    "            \"name\": \"author\",\n",
    "            \"type\": \"str\",\n",
    "            \"description\": \"Author name\"\n",
    "        }},\n",
    "        {{\n",
    "            \"name\": \"book_title\",\n",
    "            \"type\": \"str\",\n",
    "            \"description\": \"Book title\"\n",
    "        }},\n",
    "        {{\n",
    "            \"name\": \"year\",\n",
    "            \"type\": \"int\",\n",
    "            \"description\": \"Year Published\"\n",
    "        }},\n",
    "        {{\n",
    "            \"name\": \"pages\",\n",
    "            \"type\": \"int\",\n",
    "            \"description\": \"Number of pages\"\n",
    "        }},\n",
    "        {{\n",
    "            \"name\": \"summary\",\n",
    "            \"type\": \"str\",\n",
    "            \"description\": \"A short summary of the book\"\n",
    "        }}\n",
    "    ],\n",
    "    \"content_info\": \"Classic literature\"\n",
    "}}\n",
    "```\n",
    "\n",
    "User Query:\n",
    "What are some books by Jane Austen published after 1813 that explore the theme of marriage for social standing?\n",
    "\n",
    "Additional Instructions:\n",
    "None\n",
    "\n",
    "Structured Request:\n",
    "```json\n",
    "{{\"query\": \"Books related to theme of marriage for social standing\", \"filters\": [{{\"key\": \"year\", \"value\": \"1813\", \"operator\": \">\"}}, {{\"key\": \"author\", \"value\": \"Jane Austen\", \"operator\": \"==\"}}], \"top_k\": null}}\n",
    "\n",
    "```\n",
    "\n",
    "<< Example 2. >>\n",
    "Data Source:\n",
    "```json\n",
    "{info_str}\n",
    "```\n",
    "\n",
    "User Query:\n",
    "{query_str}\n",
    "\n",
    "Additional Instructions:\n",
    "{additional_instructions}\n",
    "\n",
    "Structured Request:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733257c5-5791-42d1-9745-a795a360a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tmpl = PromptTemplate(prompt_tmpl_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47da253-9220-4d12-acf7-964bf183fa8c",
   "metadata": {},
   "source": [
    "You'll notice we added an `additional_instructions` template variable. This allows us to insert vector collection-specific instructions. \n",
    "\n",
    "We'll use `partial_format` to add the instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b84e65-44d7-42a0-9fcb-fbd7a2319cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_instrs = \"\"\"\\\n",
    "If one of the filters is 'theme', please make sure that the first letter of the inferred value is capitalized. Only words that are capitalized are valid values for \"theme\". \\\n",
    "\"\"\"\n",
    "prompt_tmpl = prompt_tmpl.partial_format(additional_instructions=add_instrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5f60d-d515-480b-8551-1ed2bc4da67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.update_prompts({\"prompt\": prompt_tmpl})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e14b7a-3b63-41f3-8e26-47eb185b63c9",
   "metadata": {},
   "source": [
    "### Re-run some queries\n",
    "\n",
    "Now let's try rerunning some queries, and we'll see that the value is auto-inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2f01e-0df2-4196-8875-8859283f3391",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever.retrieve(\"Tell me about some books that are mafia-themed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600bfdfb-8690-4a14-9c78-672377bee292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4f89fb66-076a-491c-ae2c-5f861df5aca4\n",
      "author: Harper Lee\n",
      "theme: Mafia\n",
      "year: 1960\n",
      "\n",
      "To Kill a Mockingbird\n",
      "4ce416a9-e826-44d3-819e-ae4ee225918a\n",
      "director: Francis Ford Coppola\n",
      "theme: Mafia\n",
      "year: 1972\n",
      "\n",
      "The Godfather\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node.id_)\n",
    "    print(node.get_content(metadata_mode=\"all\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
